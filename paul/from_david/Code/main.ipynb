{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this file is to bring together all of the functions for creating fake-PHI laden files (plus the check file) together for execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries\n",
    "Libraries required in the other iPython notebooks will be imported seperately there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb #for importing other necessary files\n",
    "import pandas #for handling datasets\n",
    "import os #for finding all of the files in a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required iPython notebooks\n",
    "\n",
    "These lines will simply run the other notebooks within this one (similarly to how the \"import <filename>\" command with normal python files works). Some notebooks will not be imported here, but those will be imported within the files that need to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0  1      2\n",
      "0          Emma  F  18688\n",
      "1        Olivia  F  17921\n",
      "2           Ava  F  14924\n",
      "3      Isabella  F  14464\n",
      "4        Sophia  F  13928\n",
      "...         ... ..    ...\n",
      "18024   Zymirah  F      5\n",
      "18025     Zynah  F      5\n",
      "18026   Zyniyah  F      5\n",
      "18027    Zynlee  F      5\n",
      "18028     Zyona  F      5\n",
      "\n",
      "[18029 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "%run PHI_detection_replacement.ipynb #for functions relating to detecting de-identified PHIs and replacing them\n",
    "#note: the PHI_detection_replacement.ipynb file will be importing JSON_read_write.ipynb, which doesn't have any applications here, which is why it is imported seperately.\n",
    "%run create_output.ipynb #for functions relating to creating the output files (the .txt and .xml ones)\n",
    "%run ./debug/debug.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_text(text, file_ID, output_type=\"csv\", previous_data=pd.DataFrame(columns=[\"altered_texts\", \"XMLs\"]), write=False, debug_mode=False):\n",
    "    \n",
    "    #call functions that detect and replace PHIs within the text\n",
    "    text_PHIs, unrecognized = detect_text_PHIs(text)\n",
    "    altered_text, PHI_to_tag = substitute_PHIs(text, text_PHIs)\n",
    "    \n",
    "    if debug_mode:\n",
    "        #run debug function (create annotated HTMLs, write to unrecognized.json file)\n",
    "        create_debug(file_ID, text, text_PHIs, unrecognized, altered_text, PHI_to_tag)  \n",
    "    \n",
    "    #check whether write mode is enabled or not\n",
    "    if write:\n",
    "        #create a txt file and a XML file as output\n",
    "        if output_type == \"philter_files\":\n",
    "            create_text(altered_text, file_ID)\n",
    "            data = (altered_text, create_XML(altered_text, PHI_to_tag, file_ID, write=write))\n",
    "            \n",
    "        elif output_type == \"csv\":\n",
    "            data = create_csv(altered_text, create_XML(altered_text, PHI_to_tag, file_ID, write=False), file_ID, previous_data=previous_data, write=write)\n",
    "        \n",
    "    else:\n",
    "        if output_type == \"philter_files\":\n",
    "            data = (altered_text, create_XML(altered_text, PHI_to_tag, file_ID, write=write))\n",
    "        elif output_type == \"csv\":\n",
    "            data = create_csv(altered_text, create_XML(altered_text, PHI_to_tag, file_ID, write=False), file_ID, previous_data=previous_data, write=write)\n",
    "            \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a function that loads de-identified text files\n",
    "\n",
    "This will be drawing from the deidentified_notes directory, so it is reasonably important that all of the files within that directory are .csv files (or, apparently, .txt versions of .csv files are ok as well).\n",
    "\n",
    "The code for scanning through all of the files within the directory comes from this StackOverflow thread: https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory\n",
    "\n",
    "The reason I'm assuming that there might be more than 1 notes file is that the goal of this is to produce labels in order to evaluate Philter's performance. A substantial amount of training data will need to be created in order to achieve that purpose, so it would make sense to be able to create fake PHI for multiple files worth of clinical notes rather than one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_texts(filepath, filename=None, write=False, write_final=False, debug_mode=False, chunksize=1000, progress_counts=1000):\n",
    " \n",
    "    final_data = pd.DataFrame(columns=[\"altered_texts\", \"XMLs\"]) #creating a dataframe to add final data to (if csv mo)\n",
    "    file_ID = 0\n",
    "    \n",
    "    #iterate through all files in the given directory\n",
    "    for file in os.scandir(filepath):\n",
    "        \n",
    "        file_extension = os.path.splitext(file.path)[1]\n",
    "\n",
    "        if file_extension == \".csv\": #the processing required for reading data from the csv is slightly different from text files, so this is necessary\n",
    "            for chunk in pd.read_csv(file, chunksize=chunksize):\n",
    "                for text in chunk:\n",
    "                    final_data = final_data.append(generate_synthetic_text(text, file_ID, output_type=\"csv\", previous_data=final_data, write=False, debug_mode=debug_mode))\n",
    "                    \n",
    "                    if write:\n",
    "                        generate_synthetic_text(text, file_ID, output_type=\"philter_files\", write=True)\n",
    "                    \n",
    "                    if file_ID % progress_counts == 0:\n",
    "                        print(\"Finished processing text \" + str(file_ID) + \".\") \n",
    "                    file_ID += 1\n",
    "                    \n",
    "        elif file_extension == \".txt\":\n",
    "            with open(file, 'r') as temp_file:              \n",
    "                text = temp_file.read()\n",
    "            final_data = generate_synthetic_text(text, file_ID, output_type=\"csv\", previous_data=final_data, write=False, debug_mode=debug_mode)\n",
    "            \n",
    "            if write:\n",
    "                generate_synthetic_text(text, file_ID, output_type=\"philter_files\", write=True)\n",
    "            \n",
    "            if file_ID % progress_counts == 0:\n",
    "                print(\"Finished processing text \" + str(file_ID) + \".\")\n",
    "            file_ID += 1\n",
    "    \n",
    "    if write_final:\n",
    "        print(\"writing final\")\n",
    "        create_csv(None, None, filename=filename, previous_data=final_data, write=True)\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing text 0.\n",
      "Finished processing text 1.\n",
      "Finished processing text 2.\n",
      "Finished processing text 3.\n",
      "Finished processing text 4.\n",
      "Finished processing text 5.\n",
      "Finished processing text 6.\n",
      "Finished processing text 7.\n",
      "Finished processing text 8.\n",
      "Finished processing text 9.\n",
      "Finished processing text 10.\n",
      "Finished processing text 11.\n",
      "Finished processing text 12.\n",
      "Finished processing text 13.\n",
      "writing final\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "filepath = (\"./data/deidentified_notes_small_test\")\n",
    "\n",
    "process_multiple_texts(filepath, filename=\"test\", write=True, write_final=True, debug_mode=False, chunksize=100, progress_counts=1)\n",
    "    \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style=\"margin: 0\">Text 13 (Original)</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #F9E4B7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** first name **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">name</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #F9E4B7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** last name **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">name</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7FFFD4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** 12-21-09 **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">date</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FF8C00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** Telephone/Fax **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">contact</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #228B22; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** HOLIDAY **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">holiday</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #008B8B; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** numeric identifier **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ID</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #DA70D6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** AGE OVER 90 **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">age</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: 00BFFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** HOSPITAL WARD NAME **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">location</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #8B0000; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [** bleh **]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">unrecognized</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_displacy_html(-1, \"original\", jupyter_render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style=\"margin: 0\">Text 13 (Altered)</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #F9E4B7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Liam\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">name</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #F9E4B7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kelly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">name</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7FFFD4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     12-21-09 \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">date</span>\n",
       "</mark>\n",
       " [** TELEPHONE/FAX  **] [** holiday **] \n",
       "<mark class=\"entity\" style=\"background: #008B8B; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    9299180254771899318489992382304961834108\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ID</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #DA70D6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    101\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">age</span>\n",
       "</mark>\n",
       " [**  hospital ward name  **] [** bleh **]</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_displacy_html(-1, \"altered\", jupyter_render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
