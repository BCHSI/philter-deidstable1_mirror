{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this file is to contain all of the functions relating to detecting PHIs and their types within given datasets as well as to call fake_PHI_generation.ipynb's functions and prepare for file creation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb #for importing other iPython notebooks\n",
    "import re #for detecting PHIs and their types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For debugging purposes only\n",
    "\n",
    "In order to test that the generator function calls are working, fake_PHI_generation.ipynb must be imported into this file. However, this shouldn't be done when main.ipynb runs this file, so there will be an if statement gate that should be set to False when not debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required iPython notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run fake_PHI_generation.ipynb #for functions relating to generating synthetic PHIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a function that detects PHIs and their types\n",
    "\n",
    "This function will use regular expressions to find PHI markers within Philter's output files (the original ones, with brackets and stars to denote PHI locations) as well as what types of PHI each of them are (name, date, etc.).\n",
    "\n",
    "Currently, PHI will be randomized for every instance one is detected. For example, all names will be randomized, no matter if the PHI tag in the MIMIC dataset is the same. This ensures the utmost security as any names that slip through will be indistinguishable from the randomly generated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_PHIs(text):\n",
    "    #here, text is the text of a single clinical note (already de-identified)\n",
    "    \n",
    "    #list to track all of the PHIs within a single clinical note\n",
    "    text_PHIs = [] \n",
    "    \n",
    "    #PHI_list: general format\n",
    "    '''\n",
    "    [\n",
    "        {\n",
    "            \"location\": match.span() (tuple containing the start and end locations of the PHI)\n",
    "            \"type\": \"name\", \"date\", \"patient number\", etc.\n",
    "            \"subtype\": varies depending on broad type, but this should help with making synthetic generation more realistic later on\n",
    "            \"modifiers\": this is a dictionary that can be filled anything, in case there is a desire to implement more features\n",
    "            \"text\": physical texts of the PHI (not including \"[**\" and \"**]\") - in case it is needed later on\n",
    "        }\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    #for detecting all instances where \"[** ... **]\" exists - these are where PHIs are located (also has to detect trouble characters)\n",
    "    pattern = re.compile('''\\[\\*\\*.*?\\*\\*\\]|&|<|>|\"|''' + \"'\")\n",
    "    \n",
    "    #variable to ensure that entries in the PHI dictionary have unique keys (because of the way python's dict.update() function works)\n",
    "    number = 0\n",
    "    \n",
    "    #list of unrecognized PHIs (for debugging)\n",
    "    unrecognized = []\n",
    "    \n",
    "    #searching through all PHIs for their location, type, and subtype\n",
    "    for match in pattern.finditer(text):\n",
    "        \n",
    "        #figure out whether the match is a PHI or a trouble character and define test_text accordingly\n",
    "        if re.compile('\\[\\*\\*.*?\\*\\*\\]').search(match.group()) != None:\n",
    "            test_text = match.group()[3:-3].lower() #since the starting and ending sequences for PHI's are 3 characters long, doing this isolates just the text in the middle of the indicators\n",
    "        else:\n",
    "            test_text = match.group()        \n",
    "        \n",
    "        #dates\n",
    "        date_pattern = re.compile('[0-9]+\\-[0-9]+\\-[0-9]+|[0-9]+/[0-9]+/[0-9]+') #for dates, which seem to come in the format YYYY-MM-DD, but I made it more flexible just in case\n",
    "        second_date_pattern = re.compile('[0-9]+\\-[0-9]+|[0-9]+/[0-9]+')#this is an alternate date type, which seems to be MM-DD (variants with / instead of - are also accounted for)\n",
    "        third_date_pattern = re.compile('date|month|year|january|february|march|april|may|june|july|august|september|october|november|december', re.IGNORECASE) #for date ranges and dates that just say \"month (only)\", \"year (only)\", and month names\n",
    "        fourth_date_pattern = re.compile('[0-9][0-9][0-9][0-9]') #this is for another alternate date type, which seems to be YYYY\n",
    "        date_range_pattern = re.compile('range', re.IGNORECASE) #this is so that date ranges will actually be converted to date ranges and not just a single date\n",
    "        \n",
    "        #names\n",
    "        name_pattern = re.compile('name', re.IGNORECASE) #searches for the word \"name\" (i.e. doctor and patient names), regardless of case\n",
    "        gender_name_patterns = [re.compile('male', re.IGNORECASE), re.compile('female', re.IGNORECASE)]  #these regular expressions could technically be made different variables, but I think this is a bit clearer in terms of the grouping\n",
    "        format_name_patterns = [re.compile('first', re.IGNORECASE), re.compile('last', re.IGNORECASE)] #these regular expressions aim to capture instances where the tag is only for a first or last name\n",
    "            \n",
    "        #holidays\n",
    "        holiday_pattern = re.compile('holiday', re.IGNORECASE) #searches for the word \"holiday\", regardless of case\n",
    "        \n",
    "        #contact information\n",
    "        email_pattern = re.compile('email', re.IGNORECASE) #searches for the word \"email\" (not just address, as this would catch street addresses as well)\n",
    "        contact_pattern = re.compile('info', re.IGNORECASE) #searches for the word \"info\" (there are many variations of this extremely vague tag, and it will be replaced by a phone number or email address at random)\n",
    "        phone_pattern = re.compile('phone', re.IGNORECASE) #searches for the word \"phone\", which should usually catch both phone and fax numbers\n",
    "        pager_pattern = re.compile('pager', re.IGNORECASE) #searches for the word \"pager\", regardless of case\n",
    "        url_pattern = re.compile('url', re.IGNORECASE) #searches for the word \"url\", regardless of case\n",
    "        \n",
    "        #IDs (generally numbers)\n",
    "        numeric_identifier_pattern = re.compile('numeric.*?identifier', re.IGNORECASE) #searches for \"numeric identifier\" with any number of characters in between (in case there are spaces or something) \n",
    "        social_security_pattern = re.compile('social.*?security', re.IGNORECASE) #searches for \"social security\" with any number of characters in between\n",
    "        provider_pattern = re.compile('provider', re.IGNORECASE) #searches for the word \"provider\", regardless of case\n",
    "        medical_record_pattern = re.compile('medical.*?record', re.IGNORECASE) #searches for \"medical record\" with any number of characters in between\n",
    "        md_number_pattern = re.compile('md.*?number', re.IGNORECASE) #searches for \"md number\" with any number of characters in between\n",
    "        job_number_pattern = re.compile('job.*?number', re.IGNORECASE) #searches for \"job number\" with any number of characters in between\n",
    "        clip_number_pattern = re.compile('clip.*?number', re.IGNORECASE) #searches for \"clip number\" with any number of characters in between\n",
    "        \n",
    "        #ages (over 90 only)\n",
    "        age_pattern = re.compile('age', re.IGNORECASE) #this only needs to detect \"age\" since all obscured ages are those of patients over 90 years old\n",
    "        \n",
    "        #locations\n",
    "        hospital_pattern = re.compile('hospital|ward|unit', re.IGNORECASE) #searches for the various terms associated with hospital locations\n",
    "        hospital_modifier_patterns = [re.compile('ward', re.IGNORECASE), re.compile('unit', re.IGNORECASE)] #searches for the modifiers associated with hospital locations\n",
    "        home_pattern = re.compile('home|address|zip.*?code|state|country', re.IGNORECASE) #searches for the various terms associated with home locations\n",
    "        work_pattern = re.compile('work|university', re.IGNORECASE) #searches for the various terms associated with work locations\n",
    "        po_box_pattern = re.compile('p.*?o.*?.*?box', re.IGNORECASE) #searches for \"po box\" with any number of characters in between\n",
    "        address_pattern = re.compile('address', re.IGNORECASE) #searches for the word \"address\", regardless of case\n",
    "        number_pattern = re.compile('number', re.IGNORECASE) #searches for the word \"number\", regardless of case\n",
    "        location_pattern = re.compile('location', re.IGNORECASE) #searches for the word \"location\", regardless of case\n",
    "        \n",
    "        #create a variable and a dictionary so that subtypes and modifiers can be added (for extra detail about a given PHI)\n",
    "        subtype = None #setting this to None initially; will be modified by the code below if necessary\n",
    "        modifiers = {} #setting this to an empty dictionary - the reason it isn't initially set to None is so that the dictionary can be updated with something like modifiers[\"key\"]:value in the code\n",
    "        unrecognized = [] #to make sure no \n",
    "        \n",
    "        #use the text of the PHI to determine its broad type (date, name, phone number, other number, etc.)\n",
    "        \n",
    "        #dates (subtypes: range)\n",
    "        if date_pattern.search(test_text) != None or second_date_pattern.search(test_text) != None or third_date_pattern.search(test_text) != None or fourth_date_pattern.match(test_text) != None:\n",
    "            TYPE = \"date\"\n",
    "            \n",
    "            #seeing whether the date given is in the form of a date range (since ranges will have to be treated differently)\n",
    "            if date_range_pattern.search(test_text) != None:\n",
    "                subtype = \"range\"\n",
    "        \n",
    "        #names (subtypes: patient, doctor; modifiers: gender (male, female, unknown))\n",
    "        elif (name_pattern.search(test_text) != None) and hospital_pattern.search(test_text) == None:\n",
    "            TYPE = \"name\"\n",
    "                \n",
    "            #checking gender of the person (if one is not detected, then leave as None)\n",
    "            if gender_name_patterns[0].search(test_text) != None:\n",
    "                modifiers[\"gender\"] = \"male\"\n",
    "            elif gender_name_patterns[1].search(test_text)!= None:\n",
    "                modifiers[\"gender\"] = \"female\"\n",
    "            else:\n",
    "                modifiers[\"gender\"] = None\n",
    "                \n",
    "            #checking whether the name tag is only for a first or last name\n",
    "            if format_name_patterns[0].search(test_text) != None:\n",
    "                modifiers[\"format\"] = \"first\"\n",
    "            elif format_name_patterns[1].search(test_text) != None:\n",
    "                modifiers[\"format\"] = \"last\"\n",
    "            else:\n",
    "                modifiers[\"format\"] = None\n",
    "        \n",
    "        #holidays (no subtypes)\n",
    "        elif holiday_pattern.search(test_text) != None:\n",
    "            TYPE = \"holiday\"\n",
    "        \n",
    "        #contact information (subtypes: email, contact (a bit vague in my opinion as well), phone, pager, url)\n",
    "        elif email_pattern.search(test_text) != None or contact_pattern.search(test_text) != None or phone_pattern.search(test_text) != None or pager_pattern.search(test_text) != None or url_pattern.search(test_text) != None:\n",
    "            TYPE = \"contact\"\n",
    "            \n",
    "            #checking contact category subtypes\n",
    "            if email_pattern.search(test_text) != None:\n",
    "                subtype = \"email\"\n",
    "            elif contact_pattern.search(test_text) != None:\n",
    "                subtype = \"contact\"\n",
    "            elif phone_pattern.search(test_text) != None:\n",
    "                subtype = \"phone\"\n",
    "            elif pager_pattern.search(test_text) != None:\n",
    "                subtype = \"pager\"\n",
    "            else:\n",
    "                subtype = \"url\"\n",
    "            \n",
    "        #identification (subtypes: numeric_identifier, social_security_number, provider_number, medical_record_number)\n",
    "        elif numeric_identifier_pattern.search(test_text) != None or social_security_pattern.search(test_text) != None or provider_pattern.search(test_text) != None or medical_record_pattern.search(test_text) != None or md_number_pattern.search(test_text) != None or job_number_pattern.search(test_text) != None or clip_number_pattern.search(test_text) != None:\n",
    "            TYPE = \"ID\"\n",
    "            \n",
    "            #checking identifier category subtypes\n",
    "            if numeric_identifier_pattern.search(test_text) != None:\n",
    "                subtype = \"numeric_identifier\"\n",
    "            elif social_security_pattern.search(test_text) != None:\n",
    "                subtype = \"social_security_number\"\n",
    "            elif provider_pattern.search(test_text) != None:\n",
    "                subtype = \"provider_number\"\n",
    "            elif medical_record_pattern.search(test_text) != None:\n",
    "                subtype = \"medical_record_number\"\n",
    "            elif md_number_pattern.search(test_text) != None:\n",
    "                subtype = \"md_number\"\n",
    "            elif job_number_pattern.search(test_text) != None:\n",
    "                subtype = \"job_number\"\n",
    "            else:\n",
    "                subtype = \"clip_number\"\n",
    "        \n",
    "        #age (no subtypes)\n",
    "        elif age_pattern.search(test_text) != None:\n",
    "            TYPE = \"age\"\n",
    "        \n",
    "        #locations (subtypes: hospital, home, work, other; modifiers: ward, unit, name, number, address) - a bit oversimplified but plenty satisfactory for Philter (not to mention those more complex versions will be randomly generated anyway)\n",
    "        elif hospital_pattern.search(test_text) != None or home_pattern.search(test_text) != None or work_pattern.search(test_text) != None or po_box_pattern.search(test_text) != None or location_pattern.search(test_text) != None:\n",
    "            TYPE = \"location\"\n",
    "            \n",
    "            #checking location category subtypes\n",
    "            if hospital_pattern.search(test_text) != None:\n",
    "                subtype = \"hospital\"\n",
    "                #checking if the hospital location is a unit or ward\n",
    "                if hospital_modifier_patterns[0].search(test_text) != None:\n",
    "                    modifiers[\"hospital_subtype\"] = \"ward\"\n",
    "                else:\n",
    "                    modifiers[\"hospital_subtype\"] = \"unit\"\n",
    "            elif home_pattern.search(test_text) != None:\n",
    "                subtype = \"home\"\n",
    "            elif work_pattern.search(test_text) != None:\n",
    "                subtype = \"work\"\n",
    "            elif location_pattern.search(test_text) != None:\n",
    "                subtype = \"unknown\"\n",
    "            else:\n",
    "                subtype = \"other\"\n",
    "            \n",
    "            #checking location category modifiers\n",
    "            if name_pattern.search(test_text) != None:\n",
    "                modifiers[\"location_type\"] = \"name\"\n",
    "            elif address_pattern.search(test_text) != None:\n",
    "                modifiers[\"location_type\"] = \"address\"\n",
    "            elif number_pattern.search(test_text) != None:\n",
    "                modifiers[\"location_type\"] = \"number\"     \n",
    "        \n",
    "        elif test_text in [\"&\", \"<\", \">\", '''\"''', \"'\"]:\n",
    "            TYPE = \"trouble_character\"\n",
    "        \n",
    "        #unrecognized (in addition to being added to the list of the given text's PHI, so that they can be removed, it will be added to a JSON as a sanity check to see that PHIs are being properly detected)\n",
    "        else:\n",
    "            TYPE = \"unrecognized\"\n",
    "            unrecognized.append(test_text)\n",
    "        \n",
    "        #------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        #if there is a desire to add functionality to make synthetic PHI's consistent accross multiple notes as well as occurances within the text, the code for that should probably be added here\n",
    "        #------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        #add the PHI to the dictionary for this text's PHIs (needs to be done no matter what, as the text needs to have PHIs subsituted - this will help do that)\n",
    "        text_PHIs.append({\n",
    "            \"location\": match.span(),\n",
    "            \"type\": TYPE,\n",
    "            \"subtype\": subtype,\n",
    "            \"modifiers\": modifiers,\n",
    "            \"text\": test_text,\n",
    "        })\n",
    "    \n",
    "        number += 1\n",
    "    \n",
    "    return text_PHIs, unrecognized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function that substitutes sythetic PHIs into the original text\n",
    "\n",
    "This function will handle figuring out which PHIs need to be substituted into the text, substituting those PHIs into the text.\n",
    "\n",
    "In addition to returning the text with the synthetic PHIs added in, the function will also return a dictionary containing information about the PHIs it substituted (so that the XML check file can be created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_PHIs(text, text_PHIs):\n",
    "    \n",
    "    #variable for how much the string has changed in length so that only the PHI gets substituted\n",
    "    shift = 0\n",
    "    \n",
    "    PHI_to_tag = []\n",
    "    \n",
    "    #regular expressions needed to determine whether the area around a PHI is uppercase or not\n",
    "    PHI_pattern = re.compile(\"\\[\\*\\*.*?\\*\\*\\]\")\n",
    "    capitalized_pattern = re.compile(\"[A-Z]\")\n",
    "    total_pattern = re.compile(\"[a-z]|[A-Z]\")\n",
    "    \n",
    "    for PHI in text_PHIs:\n",
    "        var = False\n",
    "        text_is_upper = False\n",
    "        \n",
    "        #determine whether the area of text around the PHI (+- 10 characters, as the PHI tag will be removed) is capitalized or not\n",
    "        test_text = text[(PHI[\"location\"][0] + shift - 10): (PHI[\"location\"][1] + shift + 10)]\n",
    "        \n",
    "        #removing PHI tags since they are typically lowercase\n",
    "        test_text = re.sub(PHI_pattern, \"\", test_text) #if we compiled this only once, this would be more effecient\n",
    "        \n",
    "        #using the ratio of capital to total letters to determine whether the area is capitalized or not\n",
    "        ratio = 0\n",
    "        if PHI[\"type\"] != \"trouble_character\" and len(re.findall(total_pattern, test_text)) != 0:\n",
    "            ratio = len(re.findall(capitalized_pattern, test_text))/len(re.findall(total_pattern, test_text))\n",
    "            if ratio >= 0.75: #threshold is currently set to 75% capitalized, but this can be changed\n",
    "                text_is_upper = True\n",
    "        \n",
    "        #generate a synthetic version of the PHI, ignoring dates, holidays, and unrecognized PHI (which we can't do anything about)\n",
    "        if PHI[\"type\"] == \"date\" and PHI[\"subtype\"] != \"range\":\n",
    "            synthetic = PHI[\"text\"]\n",
    "        elif PHI[\"text\"] == \"\":\n",
    "            synthetic = \"\"\n",
    "        elif PHI[\"type\"] == \"holiday\" or PHI[\"type\"] == \"unrecognized\":\n",
    "            synthetic = \"[**\" + PHI[\"text\"] + \"**]\"\n",
    "        elif PHI[\"type\"] == \"trouble_character\":\n",
    "            \n",
    "            original_location = PHI[\"location\"]\n",
    "            PHI[\"location\"] = (original_location[0], original_location[1])\n",
    "            \n",
    "            if PHI[\"text\"] == \"&\":\n",
    "                synthetic = \"&amp;\"\n",
    "                var = True\n",
    "            elif PHI[\"text\"] == \"<\":\n",
    "                synthetic = \"&lt;\"\n",
    "                var = True\n",
    "            elif PHI[\"text\"] == \">\":\n",
    "                synthetic = \"&gt;\"\n",
    "                var = True\n",
    "            elif PHI[\"text\"] == '''\"''':\n",
    "                synthetic = \"&quot;\"\n",
    "                var = True\n",
    "            elif PHI[\"text\"] == \"'\":\n",
    "                synthetic = \"&apos;\"\n",
    "                var = True\n",
    "        else:\n",
    "            synthetic = generator(PHI[\"type\"], PHI[\"subtype\"], PHI[\"modifiers\"], PHI[\"text\"])\n",
    "    \n",
    "        if text_is_upper:\n",
    "            synthetic = synthetic.upper()\n",
    "        \n",
    "        #define/alter variables as necessary\n",
    "        start = PHI[\"location\"][0] + shift\n",
    "        start_string = text[:start]\n",
    "        \n",
    "        \n",
    "        end_string = text[PHI[\"location\"][1] + shift:]\n",
    "        \n",
    "        #altering the shift variable according to the original and new lengths of the PHIs\n",
    "        shift -= ((PHI[\"location\"][1] - PHI[\"location\"][0]) - len(str(synthetic)))\n",
    "        \n",
    "        end = PHI[\"location\"][1] + shift\n",
    "        \n",
    "        #substitute the synthetic PHI into the text\n",
    "        text = start_string + str(synthetic) + end_string           \n",
    "        \n",
    "        if PHI[\"type\"] in [\"date\", \"age\", \"name\", \"ID\"]:\n",
    "            if PHI[\"subtype\"] != \"range\":\n",
    "                #add an entry to PHI_to_tag (for XML file creation purposes) - this might seem like a strange ordering, but this is based on the order in the example XML files\n",
    "                PHI_to_tag.append({\n",
    "                    \"type\": (PHI[\"type\"], PHI[\"subtype\"], PHI[\"modifiers\"]),\n",
    "                    \"comment\": \"\",\n",
    "                    \"end\": end,\n",
    "                    \"start\": start,\n",
    "                    \"text\": synthetic\n",
    "                })\n",
    "    \n",
    "    return text, PHI_to_tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
